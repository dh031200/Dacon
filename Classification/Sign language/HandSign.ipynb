{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed281bc-e719-4364-8e0c-4b46a6fd2b77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f36bf29-7aef-4071-ab95-d269ca875b20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec346996-6ca3-4c47-a274-a147c60c6ff2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd56a6f1-8c47-474c-ad7c-200f48aa8632",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdc23d1e-54e6-4caf-80eb-6e235e188813",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HandDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, target_transform=None):\n",
    "        self.kind = csv_file.split('.')[0]\n",
    "        self.img_labels = pd.read_csv(csv_file)\n",
    "        if self.kind == 'train':\n",
    "            self.img_labels['label'].loc[self.img_labels['label'] == '10-1'] = '0'\n",
    "            self.img_labels['label'].loc[self.img_labels['label'] == '10-2'] = '10'\n",
    "            self.img_labels['label'] = self.img_labels['label'].astype(int)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.kind,self.img_labels.iloc[idx,0])\n",
    "        img = read_image(img_path)\n",
    "        if self.kind == 'test':\n",
    "            return img / 255\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = img / 255\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f416365-749c-41ff-885b-a78ff8bec2e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3)\n",
    "        # self.conv4 = nn.Conv2d(32, 64, 3)\n",
    "        # self.conv5 = nn.Conv2d(64, 128, 3)\n",
    "        self.fc1 = nn.Linear(32 * 26 * 26, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.head = nn.Linear(32, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # x = self.pool(F.relu(self.conv4(x)))\n",
    "        # x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28fe853e-23f3-472e-a14d-ca470b496a04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            X, y = data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53825c7a-b1c8-4063-bb5c-2f6f736c27ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "820e4b4d-5a45-4223-8193-30d4ccee47f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = HandDataset(train_data)\n",
    "test_dataset = HandDataset(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66c98b91-bb7e-482c-ae60-858e955c254e",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in train_dataset]\n",
    "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in train_dataset]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])\n",
    "meanG = np.mean([m[1] for m in meanRGB])\n",
    "meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])\n",
    "stdG = np.mean([s[1] for s in stdRGB])\n",
    "stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR, meanG, meanB)\n",
    "print(stdR, stdG, stdB)\n",
    "\n",
    "hand_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((300, 300)), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomHorizontalFlip(p = 1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB]),\n",
    "])\n",
    "\n",
    "train_dataset.transform = hand_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d3d32618-3b52-44ce-98bd-ae10309cbeed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e3242dd-3dce-4dd6-8083-8279b8f3c866",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------\n",
      "loss: 2.407753 [    0/  858]\n",
      "loss: 2.404529 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.6%, Avg loss: 2.394379 \n",
      "\n",
      "Epoch 2\n",
      "-------------------\n",
      "loss: 2.385957 [    0/  858]\n",
      "loss: 2.393835 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.6%, Avg loss: 2.394140 \n",
      "\n",
      "Epoch 3\n",
      "-------------------\n",
      "loss: 2.389555 [    0/  858]\n",
      "loss: 2.402508 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.7%, Avg loss: 2.392388 \n",
      "\n",
      "Epoch 4\n",
      "-------------------\n",
      "loss: 2.386420 [    0/  858]\n",
      "loss: 2.399643 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.7%, Avg loss: 2.395076 \n",
      "\n",
      "Epoch 5\n",
      "-------------------\n",
      "loss: 2.379123 [    0/  858]\n",
      "loss: 2.388311 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.6%, Avg loss: 2.394218 \n",
      "\n",
      "Epoch 6\n",
      "-------------------\n",
      "loss: 2.388061 [    0/  858]\n",
      "loss: 2.399062 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 9.6%, Avg loss: 2.391488 \n",
      "\n",
      "Epoch 7\n",
      "-------------------\n",
      "loss: 2.383374 [    0/  858]\n",
      "loss: 2.382449 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 13.5%, Avg loss: 2.369652 \n",
      "\n",
      "Epoch 8\n",
      "-------------------\n",
      "loss: 2.359705 [    0/  858]\n",
      "loss: 2.380100 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 12.5%, Avg loss: 2.342039 \n",
      "\n",
      "Epoch 9\n",
      "-------------------\n",
      "loss: 2.335284 [    0/  858]\n",
      "loss: 2.330465 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 16.7%, Avg loss: 2.312614 \n",
      "\n",
      "Epoch 10\n",
      "-------------------\n",
      "loss: 2.281720 [    0/  858]\n",
      "loss: 2.274707 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 23.9%, Avg loss: 2.117081 \n",
      "\n",
      "Epoch 11\n",
      "-------------------\n",
      "loss: 2.092740 [    0/  858]\n",
      "loss: 2.148652 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 23.4%, Avg loss: 2.025633 \n",
      "\n",
      "Epoch 12\n",
      "-------------------\n",
      "loss: 2.026399 [    0/  858]\n",
      "loss: 2.030469 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 26.8%, Avg loss: 1.914128 \n",
      "\n",
      "Epoch 13\n",
      "-------------------\n",
      "loss: 1.803444 [    0/  858]\n",
      "loss: 1.777948 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 32.5%, Avg loss: 1.695529 \n",
      "\n",
      "Epoch 14\n",
      "-------------------\n",
      "loss: 1.625708 [    0/  858]\n",
      "loss: 1.683089 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 31.1%, Avg loss: 1.726706 \n",
      "\n",
      "Epoch 15\n",
      "-------------------\n",
      "loss: 1.756071 [    0/  858]\n",
      "loss: 1.585115 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 40.6%, Avg loss: 1.573743 \n",
      "\n",
      "Epoch 16\n",
      "-------------------\n",
      "loss: 1.683366 [    0/  858]\n",
      "loss: 1.551436 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.281723 \n",
      "\n",
      "Epoch 17\n",
      "-------------------\n",
      "loss: 1.222049 [    0/  858]\n",
      "loss: 1.479623 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 40.7%, Avg loss: 1.449642 \n",
      "\n",
      "Epoch 18\n",
      "-------------------\n",
      "loss: 1.433517 [    0/  858]\n",
      "loss: 1.095724 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 57.1%, Avg loss: 1.089352 \n",
      "\n",
      "Epoch 19\n",
      "-------------------\n",
      "loss: 1.104877 [    0/  858]\n",
      "loss: 1.051651 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.902483 \n",
      "\n",
      "Epoch 20\n",
      "-------------------\n",
      "loss: 0.895539 [    0/  858]\n",
      "loss: 0.905822 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.815290 \n",
      "\n",
      "Epoch 21\n",
      "-------------------\n",
      "loss: 0.876678 [    0/  858]\n",
      "loss: 0.854418 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 76.3%, Avg loss: 0.640894 \n",
      "\n",
      "Epoch 22\n",
      "-------------------\n",
      "loss: 0.589581 [    0/  858]\n",
      "loss: 0.747759 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.628453 \n",
      "\n",
      "Epoch 23\n",
      "-------------------\n",
      "loss: 0.649087 [    0/  858]\n",
      "loss: 0.743126 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.497703 \n",
      "\n",
      "Epoch 24\n",
      "-------------------\n",
      "loss: 0.402626 [    0/  858]\n",
      "loss: 0.426166 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.413729 \n",
      "\n",
      "Epoch 25\n",
      "-------------------\n",
      "loss: 0.441749 [    0/  858]\n",
      "loss: 0.485852 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.408965 \n",
      "\n",
      "Epoch 26\n",
      "-------------------\n",
      "loss: 0.369858 [    0/  858]\n",
      "loss: 0.347301 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.283172 \n",
      "\n",
      "Epoch 27\n",
      "-------------------\n",
      "loss: 0.230721 [    0/  858]\n",
      "loss: 0.251441 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.235236 \n",
      "\n",
      "Epoch 28\n",
      "-------------------\n",
      "loss: 0.299219 [    0/  858]\n",
      "loss: 0.283590 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.278333 \n",
      "\n",
      "Epoch 29\n",
      "-------------------\n",
      "loss: 0.190805 [    0/  858]\n",
      "loss: 0.166304 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.196420 \n",
      "\n",
      "Epoch 30\n",
      "-------------------\n",
      "loss: 0.170353 [    0/  858]\n",
      "loss: 0.214348 [  640/  858]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.207608 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(train_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "86bd45de-0ddd-4f6e-96c0-e8f24ac4bb42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "summit = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images = data.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        v = str(int(predicted.cpu()))\n",
    "        if v == '0':\n",
    "            v = '10-1'\n",
    "        elif v== '10':\n",
    "            v = '10-2'\n",
    "        summit.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "647539de-d1ec-4701-ba54-1a09ab727212",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c619c98-d7c2-4d50-855d-8fd67c0fc2d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission['label'] = summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfc8949d-0bac-4aa6-aba4-96461b1b2948",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>211.png</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>212.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>213.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>214.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>215.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_name label\n",
       "0     001.png     6\n",
       "1     002.png     8\n",
       "2     003.png     1\n",
       "3     004.png     6\n",
       "4     005.png     9\n",
       "..        ...   ...\n",
       "210   211.png     5\n",
       "211   212.png     8\n",
       "212   213.png     3\n",
       "213   214.png     6\n",
       "214   215.png     1\n",
       "\n",
       "[215 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "965d9159-bb72-4e54-932a-fadc878cb868",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('commit_1.csv', index=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d60091b0-c5d2-459f-b439-4153d7a9128e",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "num_batches = len(train_dataloader)\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train_dataloader:\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        print(correct)\n",
    "        break\n",
    "\n",
    "test_loss /= num_batches\n",
    "correct /= size\n",
    "print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f975d-45b7-4e98-ac26-f6a8603993e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6187cad-ddf7-4dda-902b-5c53cae60d73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# l = k.cpu().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18698a1c-4c43-4450-aa4d-159aac3ee94e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(l, (1, 2, 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}