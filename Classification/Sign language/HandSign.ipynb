{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed281bc-e719-4364-8e0c-4b46a6fd2b77",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f36bf29-7aef-4071-ab95-d269ca875b20",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec346996-6ca3-4c47-a274-a147c60c6ff2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = 'train.csv'\n",
    "test_data = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd56a6f1-8c47-474c-ad7c-200f48aa8632",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc23d1e-54e6-4caf-80eb-6e235e188813",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HandDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, target_transform=None):\n",
    "        self.kind = csv_file.split('.')[0]\n",
    "        self.img_labels = pd.read_csv(csv_file)\n",
    "        if self.kind == 'train':\n",
    "            self.img_labels['label'].loc[self.img_labels['label'] == '10-1'] = '0'\n",
    "            self.img_labels['label'].loc[self.img_labels['label'] == '10-2'] = '10'\n",
    "            self.img_labels['label'] = self.img_labels['label'].astype(int)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.kind,self.img_labels.iloc[idx,0])\n",
    "        img = Image.open(img_path)\n",
    "        # img = np.array(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.kind == 'test':\n",
    "            return img\n",
    "        label = self.img_labels.iloc[idx, 1].item()\n",
    "        label = np.array(label)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b199b1-f490-44a2-8ca5-0903becd710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_1 = self.Conv(3, 8)\n",
    "        self.conv_2 = self.Conv(8, 16)\n",
    "        self.conv_3 = self.Conv(16, 32)\n",
    "        self.conv_4 = self.Conv(32, 64)\n",
    "        self.conv_5 = self.Conv(64, 128)\n",
    "        self.conv_6 = self.Conv(128, 256)\n",
    "        self.gap = self.Gap()\n",
    "        self.dense_1 = self.Dense(256, 128)\n",
    "        self.dense_2 = self.Dense(128, 64)\n",
    "        self.dense_3 = self.Dense(64, 32)\n",
    "        self.dense_4 = self.Dense(32, 16)\n",
    "        # self.dense_5 = self.Dense(16, 8)\n",
    "        self.head = nn.Linear(16, 11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.conv_4(x)\n",
    "        # x = self.conv_5(x)\n",
    "        # x = self.conv_6(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0),x.size(1))\n",
    "        # x = self.dense_1(x)\n",
    "        # x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.dense_4(x)\n",
    "        # x = self.dense_5(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "        \n",
    "    def Conv(self, i_ch, o_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(i_ch, o_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Conv2d(o_ch, o_ch, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    \n",
    "    def Gap(self):\n",
    "        return nn.AdaptiveAvgPool2d((1,1))\n",
    "    \n",
    "    def Dense(self, i_ch, o_ch):\n",
    "        return nn.Sequential(\n",
    "            nn.Linear(in_features=i_ch, out_features=o_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3877bb44-9960-47ea-b6f1-2a46516e578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.fc1 = nn.Linear(56 * 56 * 16, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 11)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 224 * 224 * 8\n",
    "        x = F.relu(x)     # 224 * 224 * 8\n",
    "        x = self.pool(x)  # 112 * 112 * 8\n",
    "        x = self.conv2(x) # 112 * 112 * 16\n",
    "        x = F.relu(x)     # 112 * 112 * 16\n",
    "        x = self.pool(x)  # 56 * 56 * 16\n",
    "        \n",
    "        x = x.view(-1, 56 * 56 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28fe853e-23f3-472e-a14d-ca470b496a04",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(X)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        current_loss = loss.item()\n",
    "        total_loss += current_loss\n",
    "        \n",
    "        print('\\r train_loss: %.4f' % (total_loss/(batch+1)), end='')\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            X, y = data\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(X)\n",
    "            \n",
    "            test_loss += loss_fn(output, y).item()\n",
    "            _, pred = torch.max(output, 1)\n",
    "\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'\\r Valid Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820e4b4d-5a45-4223-8193-30d4ccee47f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729 129\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HandDataset(train_data, transform=ToTensor())\n",
    "test_dataset = HandDataset(test_data, transform=ToTensor())\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=0)\n",
    "indices = list(range(len(train_dataset)))\n",
    "y_train = [y for _, y in train_dataset]\n",
    "\n",
    "for train_index, val_index in sss.split(indices, y_train):\n",
    "    print(len(train_index), len(val_index))\n",
    "    \n",
    "train_ds = Subset(train_dataset, train_index)\n",
    "val_ds = Subset(train_dataset, val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ab4c13-5132-417b-9c0a-8caa39009d5c",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5878615 0.53980184 0.4853427\n",
      "0.15058757 0.15921523 0.17031455\n"
     ]
    }
   ],
   "source": [
    "meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in train_dataset]\n",
    "stdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in train_dataset]\n",
    "\n",
    "meanR = np.mean([m[0] for m in meanRGB])\n",
    "meanG = np.mean([m[1] for m in meanRGB])\n",
    "meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "stdR = np.mean([s[0] for s in stdRGB])\n",
    "stdG = np.mean([s[1] for s in stdRGB])\n",
    "stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "print(meanR, meanG, meanB)\n",
    "print(stdR, stdG, stdB)\n",
    "\n",
    "hand_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)), \n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomHorizontalFlip(p = 1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB]),\n",
    "])\n",
    "\n",
    "train_dataset.transform = hand_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53825c7a-b1c8-4063-bb5c-2f6f736c27ef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-3\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "\n",
    "model = Model()\n",
    "# model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d32618-3b52-44ce-98bd-ae10309cbeed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "valid_dataloader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=16)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3242dd-3dce-4dd6-8083-8279b8f3c866",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------\n",
      " train_loss: 2.4059\n",
      " Valid Accuracy: 9.2%, Avg loss: 2.398553\n",
      "Epoch 2\n",
      "-------------------\n",
      " train_loss: 2.4023\n",
      " Valid Accuracy: 9.2%, Avg loss: 2.395711\n",
      "Epoch 3\n",
      "-------------------\n",
      " train_loss: 2.3962\n",
      " Valid Accuracy: 8.1%, Avg loss: 2.394872\n",
      "Epoch 4\n",
      "-------------------\n",
      " train_loss: 2.3960\n",
      " Valid Accuracy: 9.2%, Avg loss: 2.394422\n",
      "Epoch 5\n",
      "-------------------\n",
      " train_loss: 2.3937\n",
      " Valid Accuracy: 9.3%, Avg loss: 2.393680\n",
      "Epoch 6\n",
      "-------------------\n",
      " train_loss: 2.3979\n",
      " Valid Accuracy: 9.6%, Avg loss: 2.393390\n",
      "Epoch 7\n",
      "-------------------\n",
      " train_loss: 2.3944\n",
      " Valid Accuracy: 9.6%, Avg loss: 2.393400\n",
      "Epoch 8\n",
      "-------------------\n",
      " train_loss: 2.3964\n",
      " Valid Accuracy: 9.6%, Avg loss: 2.393573\n",
      "Epoch 9\n",
      "-------------------\n",
      " train_loss: 2.3951\n",
      " Valid Accuracy: 9.6%, Avg loss: 2.393566\n",
      "Epoch 10\n",
      "-------------------\n",
      " train_loss: 2.3946\n",
      " Valid Accuracy: 9.6%, Avg loss: 2.393581\n",
      "Epoch 11\n",
      "-------------------\n",
      " train_loss: 2.3945\n",
      " Valid Accuracy: 9.7%, Avg loss: 2.393218\n",
      "Epoch 12\n",
      "-------------------\n",
      " train_loss: 2.3954\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------')\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    print('')\n",
    "    test_loop(valid_dataloader, model, loss_fn)\n",
    "    print('')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd45de-0ddd-4f6e-96c0-e8f24ac4bb42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "summit = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images = data.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        v = str(int(predicted.cpu()))\n",
    "        if v == '0':\n",
    "            v = '10-1'\n",
    "        elif v== '10':\n",
    "            v = '10-2'\n",
    "        summit.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647539de-d1ec-4701-ba54-1a09ab727212",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c619c98-d7c2-4d50-855d-8fd67c0fc2d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission['label'] = summit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8949d-0bac-4aa6-aba4-96461b1b2948",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d9159-bb72-4e54-932a-fadc878cb868",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('commit_1.csv', index=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d60091b0-c5d2-459f-b439-4153d7a9128e",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "size = len(train_dataloader.dataset)\n",
    "num_batches = len(train_dataloader)\n",
    "test_loss, correct = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in train_dataloader:\n",
    "        X, y = data\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        print(correct)\n",
    "        break\n",
    "\n",
    "test_loss /= num_batches\n",
    "correct /= size\n",
    "print(f'Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f975d-45b7-4e98-ac26-f6a8603993e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# x,y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6187cad-ddf7-4dda-902b-5c53cae60d73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# l = k.cpu().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18698a1c-4c43-4450-aa4d-159aac3ee94e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(l, (1, 2, 0)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
